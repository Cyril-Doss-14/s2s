{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define directories and parameters\n",
    "source_dir = 'processed_data'\n",
    "train_dir = 'train'\n",
    "val_dir = 'val'\n",
    "img_size = (224, 224)  # Change the input shape to (224, 224)\n",
    "batch_size = 32  # Increase batch size\n",
    "\n",
    "# Function to split data into train and val directories\n",
    "def split_data(source, train, val, split_size):\n",
    "    files = os.listdir(source)\n",
    "    random.shuffle(files)\n",
    "    split_index = int(split_size * len(files))\n",
    "    train_files = files[:split_index]\n",
    "    val_files = files[split_index:]\n",
    "\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(source, file), os.path.join(train, file))\n",
    "\n",
    "    for file in val_files:\n",
    "        shutil.copy(os.path.join(source, file), os.path.join(val, file))\n",
    "\n",
    "# Create train and val directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "for label in os.listdir(source_dir):\n",
    "    os.makedirs(os.path.join(train_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, label), exist_ok=True)\n",
    "    split_data(os.path.join(source_dir, label), os.path.join(train_dir, label), os.path.join(val_dir, label),\n",
    "               split_size=0.8)\n",
    "\n",
    "# Create data generators with prefetching for faster data loading\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ").prefetch(tf.data.AUTOTUNE)  # Add prefetching\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ").prefetch(tf.data.AUTOTUNE)  # Add prefetching\n",
    "\n",
    "# Define the number of output classes\n",
    "n_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Load MobileNetV2 as a feature extractor with the new input shape\n",
    "base_model = MobileNetV2(input_shape=(img_size[0], img_size[1], 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom layers on top of MobileNetV2 with Dropout regularization\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  # Add Dropout layer to reduce overfitting\n",
    "\n",
    "# Define the number of output classes for the final Dense layer\n",
    "predictions = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model and collect history for learning curves\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "model.save('model_mobilenetv2.keras')\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Evaluate the model on the validation data and get confidence\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f'Validation Loss: {val_loss:.4f}')\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
